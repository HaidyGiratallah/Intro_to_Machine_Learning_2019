{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "Intro_to_Machine_Learning_classification_code-along.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HaidyGiratallah/Intro_to_Machine_Learning_2019/blob/master/Intro_to_Machine_Learning_classification_code_along.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cCjKq1vw4bV",
        "colab_type": "text"
      },
      "source": [
        "# Classification using SVMs\n",
        "\n",
        "\n",
        "In this notebook we'll play around with how Machine learning models can perform classification tasks. In particular we'll explore SVM's. As with the regression module we'll employ some validation to ensure that our results generalize well. We'll also look into evaluation methods for classification models such as sensitivity, specificity and receiver operating characteristic curves. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BI5eHnUrSoSH",
        "colab_type": "text"
      },
      "source": [
        "First, as always, import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yUvMCOew4be",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wvIpai8w4br",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOTFaDxBzcWd",
        "colab_type": "text"
      },
      "source": [
        "## Importing Breast Cancer Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwOdXVU0z59B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Cancer data from SKlearn library\n",
        "# Datasets can be also found here: (http://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+%28diagnostic%29)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNIGjCPYw4cP",
        "colab_type": "text"
      },
      "source": [
        "It's a good practice when working with new datasets is to perform some visualization. While we won't have the luxury to do this with high dimensional data which is probably most contexts in which classification is performed, playing with a low-dimensional case is good for building intuition:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYgnIdP00tH-",
        "colab_type": "text"
      },
      "source": [
        "Let's view the dataset as a table. Note that our target column is coded as binary \"1, 0\" for benign vs cancerious. Which makes this a binary classification problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVCQbEHM0xw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN1HYiw8TBup",
        "colab_type": "text"
      },
      "source": [
        "Scatterplots or pairplots are very useful to visualize all your parameters or features. You can also plot corrolations between your features to help you identify important features for hyperparameter tuning or feature engineering. Here, let's assume we decided that the 'mean radius' and the 'mean concavity' are the most important features for detecting cancerious from benign tumors. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FsPfoImw4cS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muuYmkDtw4cb",
        "colab_type": "text"
      },
      "source": [
        "As you can see from the data there's some separation between both classes of the data. Our goal is to train a Support Vector Machine classifier to model the separation between the classes. As with most machine learning tools, <code>sklearn</code> also has a support vector machine classifier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faZOsPrRw4ce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6p7AMZEw4co",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cn4MqBAVOptC",
        "colab_type": "text"
      },
      "source": [
        "### Splitting your data into 'Training' and 'Testing' datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6fsq23gw4cw",
        "colab_type": "text"
      },
      "source": [
        "First let's split the dataset into a training and a testing set.\n",
        "\n",
        "N.B. There are multiple ways by which you can split your data which can further explained in validation methods. The main purpose of spliting is that you are able to hold out some data for testing your model performance on new unseen data \"for better generalizability\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reO6OnXnCval",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ArHFkNZnEXw1",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B643LaeMEh9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7L9lwcsVijq",
        "colab_type": "text"
      },
      "source": [
        "## Training your model using the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrddx4wGw4cy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GhnTHCsw4c-",
        "colab_type": "text"
      },
      "source": [
        "Now we can inspect from properties of this model to get a better idea about how it performed on our full dataset. First we'll visualize the dividing line generated by this model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hU_Z22xRw4dB",
        "colab_type": "text"
      },
      "source": [
        "First, note that since this particular SVM is a linear model, fitting the model results in a linear model much like linear regression. The only difference being is that this line is designed to cut across two classes rather than to  minimize the mean squared error as we did with linear regression:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61MqC5Czw4dE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RG7jsQuw4dN",
        "colab_type": "text"
      },
      "source": [
        "Evaluation of the model requires us to write out the equation of the plane decided by the svm model and re-arrange the equation to solve for $x_1$ or $x_2$ (both are equivalent):\n",
        "\n",
        "$$ax_1 + bx_2 + c = 0$$\n",
        "$$x_2 = \\frac{-ax_1 - c}{b}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDB_o0UZw4dQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtdrMpBYw4dZ",
        "colab_type": "text"
      },
      "source": [
        "Now that we've compute our linear boundary let's visualize what it looks like!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caSBE2lmw4db",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wS9E9L0w4dl",
        "colab_type": "text"
      },
      "source": [
        "Furthermore, we can visualize which vectors were used as support vectors as well!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "8b4HL6RRw4do",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89IcPVl3w4dx",
        "colab_type": "text"
      },
      "source": [
        "We can also plot the margins used in the SVM model as well. The margins of the SVM are described by the following equation:\n",
        "\n",
        "For the top margin:\n",
        "$$ ax_1 + bx_2 + c = 1 $$\n",
        "\n",
        "For the bottom margin:\n",
        "$$ ax_1 + bx_2 + c = -1 $$\n",
        "\n",
        "Re-arranging the equations to solve for $x_2$ as usual (for the top margin):\n",
        "\n",
        "$$x_2 = \\frac{1- ax_1 - c}{b}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkyhGMhKw4d0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0imtCP7w4d-",
        "colab_type": "text"
      },
      "source": [
        "Now we can visualize the full SVM result!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqiYtkxow4eB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6jFIU-6w4eL",
        "colab_type": "text"
      },
      "source": [
        "This visualization will becoming increasingly useful as we start thinking about regularization!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DE_2Xe9WNJlV",
        "colab_type": "text"
      },
      "source": [
        "## Let's use our trained model to make a prediction using our test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXO3EQpJGS1z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predict test set using your trained model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1Mb0g3qsOqV",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dY1sytwiw4fT",
        "colab_type": "text"
      },
      "source": [
        "### Computing Classification Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKOwU-GJw4jl",
        "colab_type": "text"
      },
      "source": [
        "Now that we've fit our model, we can start to calculate classification metrics on the test dataset. *Only metrics calculated on the test dataset are useful towards evaluating the expected performance of your model on unseen data!*. \n",
        "\n",
        "An easy way to generate these probabilities is to predict the classes in the test case, then use <code>sklearn.metrics.confusion_matrix</code> to generate our 2x2 table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BD8y4X0A04m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import metric libraries\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T59sLkbIw4kx",
        "colab_type": "text"
      },
      "source": [
        "Recall that the confusion matrix assesses in a table:\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <td> True Negatives </td>\n",
        "        <td> False Positives </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td> False Negative </td>\n",
        "        <td> True Positives </td>\n",
        "</table>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUmOP17g_0NR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create confustion matrix\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZk_-kAAJsbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print classification report\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APSXePt-w4fP",
        "colab_type": "text"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1OcJidhw4k3",
        "colab_type": "text"
      },
      "source": [
        "### Exercise:\n",
        "Using the confusion matrix table calculate:\n",
        "\n",
        "1. Accuracy on test set\n",
        "2. Specificity on test set\n",
        "3. Sensitivity on test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjgPVp-ow4k7",
        "colab_type": "text"
      },
      "source": [
        "### Solution:\n",
        "\n",
        "The following equations are used:\n",
        "\n",
        "$$\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}$$\n",
        "\n",
        "\n",
        "$$\\text{Specificity} = \\frac{TN}{TN + FP}$$\n",
        "\n",
        "\n",
        "$$\\text{Sensitivity} = \\frac{TP}{TP + FN}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pOrefYfw4lA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6ke3TBkw4lW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkEZr2fFw4lh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oXglgv-w4lr",
        "colab_type": "text"
      },
      "source": [
        "Looks like our model did pretty well! The final step is to explore the sensitivity/specificity trade-off and to plot the ROC curve. In order to explore the ROC curve we must first generate scores for each data point in the test set. Changing the threshold at which we classify data as being at class 0 or class 1 will yield the ROC curve:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoNm-39ww4lt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U46mIRYNw4l6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6sFym-8w4mM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odpv6s-iw4mf",
        "colab_type": "text"
      },
      "source": [
        "As you can see SVMs perform quite well in high dimensional space, there are some theoretical reasons why this is the case but that topic is too advanced for an intro course. We could do better by performing dimensionality reduction techniques or regularization (which is a feature that SVMs actually have built-in, see the $C$ parameter)... \n",
        "\n",
        "Finally, you might have noticed that our SVM is a linear function. However, we can extend the SVM to non-linear cases using something called the **Kernel Trick**. We won't get into it in this course but the **Kernel Trick** is an extraordinary property of the SVM that allows it to be widely applicable!"
      ]
    }
  ]
}